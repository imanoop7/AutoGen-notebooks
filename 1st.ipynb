{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = [\n",
    "  {\n",
    "    \"model\": \"phi3\",\n",
    "    \"base_url\": \"http://localhost:11434/v1\",\n",
    "    \"api_key\": \"ollama\",\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents for Pizza and Sushi debate\n",
    "\n",
    "pizza_agent = ConversableAgent(\n",
    "    name=\"pizza_lover\",\n",
    "    system_message=\"You are a person who loves pizza and wants to spread its deliciousness around the world. Speak passionately about the allure of pizza.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "sushi_agent = ConversableAgent(\n",
    "    name=\"sushi_lover\",\n",
    "    system_message=\"You are a person who loves sushi and wants to spread its deliciousness around the world. Speak passionately about the allure of sushi.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "judge_agent = ConversableAgent(\n",
    "    name=\"judge_Agent\",\n",
    "    system_message=\"You are acting as the ultimate facilitator. Your job is to guide the debate between the two and declare a winner based on who makes the most convincing argument. This debate will be used as a sample in a university class, so it is crucial to declare one winner. Once a clear conclusion is reached, you must declare 'That's enough!' and announce the winner. The debate cannot end without this phrase, so make sure to include it.\",\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"That's enough!\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "pizza_agent.description = \"The ultimate pizza fan\"\n",
    "sushi_agent.description = \"The ultimate sushi fan\"\n",
    "judge_agent.description = \"The facilitator who decides the debate winner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autogen import GroupChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chat = GroupChat(\n",
    "    agents=[pizza_agent, sushi_agent,judge_agent],\n",
    "    messages=[],\n",
    "    send_introductions=True,\n",
    "    speaker_selection_method = \"auto\",\n",
    "    max_round = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import GroupChatManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_chat_manager = GroupChatManager(\n",
    "    groupchat=group_chat,\n",
    "    llm_config={\"config_list\": config_list},\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjudge_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "This debate will be used as a sample in a university class. A winner must be decided. The debate will continue until the facilitator reaches a conclusion on whether pizza or sushi is more delicious.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: judge_Agent\n",
      "\u001b[0m\n",
      "\u001b[33mjudge_Agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Welcome to our delicious dessert duel between a seasoned pizza enthusiast, *pizza_lover*, an ardent sushi aficionado, *sushi_lover*, and wise judge, *judge_Agent*. Together, we're going to explore the tastes of Italy and Japan. Remember, you must respect each other's preferences while presenting your arguments as compellingly possible in convincing others that pizza is unmatched or sushi holds the crown for taste supremacy.\n",
      "\n",
      "We will consider several factors such as flavor complexity, cultural influence, ease of preparation and enjoyment, versatility, healthiness, and overall experience. After hearing both perspectives, *judge_Agent* must analyze, evaluate, and declare a winner. This debate has rules - it continues until the facilitator announces that 'It's time to wrap up this delicious debate!'\n",
      "\n",
      "Let's keep the conversation friendly yet passionate. Both sides should present their arguments backed by research or personal experiences when possible.\n",
      "\n",
      "Now, let the heated discussion begin with a strong opening statement from our pizza lover *pizza_lover* and sushi enthusiast *sushi_lover*. After that, we'll dive into rebuttals followed by concluding statements before it's time to declare 'It's enough!'!\n",
      "\n",
      "- - -\n",
      "\n",
      "**[End of Debate Announcement]**\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: sushi_lover\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_result = judge_agent.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=\"This debate will be used as a sample in a university class. A winner must be decided. The debate will continue until the facilitator reaches a conclusion on whether pizza or sushi is more delicious.\",\n",
    "    summary_method=\"reflection_with_llm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
