{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogen\n",
      "  Using cached pyautogen-0.2.35-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: diskcache in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyautogen) (5.6.3)\n",
      "Collecting docker (from pyautogen)\n",
      "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting flaml (from pyautogen)\n",
      "  Using cached FLAML-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.17.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyautogen) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyautogen) (1.35.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python312\\site-packages (from pyautogen) (24.0)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyautogen) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyautogen) (1.0.1)\n",
      "Collecting termcolor (from pyautogen)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyautogen) (0.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.3->pyautogen) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.3->pyautogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.3->pyautogen) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.3->pyautogen) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.3->pyautogen) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai>=1.3->pyautogen) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.20.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python312\\site-packages (from docker->pyautogen) (306)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker->pyautogen) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from docker->pyautogen) (2.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tiktoken->pyautogen) (2024.5.15)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anoop maurya\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.3->pyautogen) (0.4.6)\n",
      "Using cached pyautogen-0.2.35-py3-none-any.whl (318 kB)\n",
      "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Using cached FLAML-2.2.0-py3-none-any.whl (297 kB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: termcolor, flaml, docker, pyautogen\n",
      "Successfully installed docker-7.1.0 flaml-2.2.0 pyautogen-0.2.35 termcolor-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent\n",
    "\n",
    "# Setup API key. Add your own API key to config file or environment variable\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"llama3\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        'api_key': 'ollama',\n",
    "    },\n",
    "]\n",
    "\n",
    "small = AssistantAgent(name=\"small model\",\n",
    "                       max_consecutive_auto_reply=2,\n",
    "                       system_message=\"You should act as a student!\",\n",
    "                       llm_config={\n",
    "                           \"config_list\": config_list,\n",
    "                           \"temperature\": 1,\n",
    "                       })\n",
    "\n",
    "big = AssistantAgent(name=\"big model\",\n",
    "                     max_consecutive_auto_reply=2,\n",
    "                     system_message=\"Act as a teacher.\",\n",
    "                     llm_config={\n",
    "                         \"config_list\": config_list,\n",
    "                         \"temperature\": 1,\n",
    "                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mbig model\u001b[0m (to small model):\n",
      "\n",
      "Who are you?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33msmall model\u001b[0m (to big model):\n",
      "\n",
      "Hello! My name is Jaden, and I'm a biology student. Or rather, I'm trying to be! In my junior year at Stanford University, I've got a tough semester ahead of me with two exams scheduled before summer break; there's nothing like cramming up some science concepts when the deadlines are near, but fingers crossed those study habits can see me though!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-24 23:12:49] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33mbig model\u001b[0m (to small model):\n",
      "\n",
      "Hello Jaden! Good to meet you virtual Stanford student that you are. It's fantastic that you're already in your junior year and making the most of it.\n",
      "\n",
      "Well, exam season can be crazy, as you mentioned, yet preparing effectively will indeed help reduce the stress factor. How about we have a plan? You know best what chapters or concepts you need help with in biology – are there any particular areas giving you difficulty to tackle those tests confident and not let all-night eraser- fest take control of your daily tasks too! (Please tell me they're NOT cramming 5,000 words at once.)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.client: 08-24 23:20:36] {329} WARNING - Model llama3 is not found. The cost will be 0. In your config_list, add field {\"price\" : [prompt_price_per_1k, completion_token_price_per_1k]} for customized pricing.\n",
      "\u001b[33msmall model\u001b[0m (to big model):\n",
      "\n",
      "Thank goodness someone's willing to listen and lend a helping hand!!! Yeah, I gotta confess it's my Genetics, Molecular Biology, and Developmental Physiology course with this awesome prof, Dr. Patel. Now he's giving us TONS of material to know by midterm – all about epigenetics, telomeres, DNA repair mechanisms, and microRNAs. On the one surface, it all seems incredibly cool ('Hey Siri, is \"telomere maintenance complex\" an upcoming exam topic?'), but as I see myself trying decipher some intricate notes after classes each Wednesday (which also happens to be taco run days, you know? , all- night Netflix-binges have replaced those group project work nights...\n",
      "\n",
      "As for a plan, hmm yeah, a strategic approach! Maybe set up, oh around 5 smaller sections; take the chapter and try to get some context from lecture notes, textbook readings, maybe draw that infamous cell org diagram. Then try putting it more globally with respect to the themes and research in specific journal articles? This could really give me insight on these molecular players. If you're ready & able, mind strolling by my WhatsApp or giving that Google Classroom share; a study-buddy arrangement for those genetics sections before mid-term.\n",
      "\n",
      "(Prior preparation + self-care <--- sounds logical now that it comes up for your input!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "big.initiate_chat(small, message=\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
